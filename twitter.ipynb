{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-snowboard",
   "metadata": {},
   "source": [
    "# Polarization on Twitter\n",
    "### By Jonathan Gustafsson Frennert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-makeup",
   "metadata": {},
   "source": [
    "### I. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from scipy.stats import mstats\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All packages imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-scoop",
   "metadata": {},
   "source": [
    "### II. Matplotlib Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams['font.size'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latex document Text width\n",
    "latex_width = 390.0\n",
    "\n",
    "def set_size(width=latex_width, height=latex_width, fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "    \n",
    "    Credit to Jack Walton for the function.\n",
    "    Source: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "    \"\"\"\n",
    "\n",
    "    fig_width_pt = width * fraction\n",
    "    fig_height_pt = height * fraction\n",
    "    \n",
    "    inches_per_pt = 1 / 72.27\n",
    "    \n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_height_pt * inches_per_pt * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-police",
   "metadata": {},
   "source": [
    "## III. Color Palette\n",
    "\n",
    "The palette is from the [iWantHue](http://medialab.github.io/iwanthue/) website by Mathieu Jacomy at the Sciences-Po Medialab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "determined-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#ba4c40\",\n",
    "    \"#45c097\",\n",
    "    \"#573485\",\n",
    "    \"#a8ae3e\",\n",
    "    \"#8874d9\",\n",
    "    \"#69a050\",\n",
    "    \"#be64b2\",\n",
    "    \"#bc7d36\",\n",
    "    \"#5d8ad4\",\n",
    "    \"#b94973\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-housing",
   "metadata": {},
   "source": [
    "## IV. Twitter Dataset\n",
    "\n",
    "**Provenance:** Ibrahim Sabuncu, \"USA Nov.2020 Election 20 Mil. Tweets (with Sentiment and Party Name Labels) Dataset.\" *IEEE Dataport*, 14 Aug. 2020, doi: https://dx.doi.org/10.21227/25te-j338.\n",
    "\n",
    "**License:** [Developer Agreement](https://developer.twitter.com/en/developer-terms/agreement)\n",
    "\n",
    "**Usage Information:** \n",
    "- \"you may only use the following information for non-commercial, internal purposes (e.g., to improve the functionality of the Services): (a) aggregate Twitter Applications user metrics, such as number of active users or accounts on Twitter Applications; (b) the responsiveness of Twitter Applications; and (c) results, usage statistics, data or other information (in the aggregate or otherwise) derived from analyzing, using, or regarding the performance of the Twitter API.\"\n",
    "\n",
    "- \"you may not use, or knowingly display, distribute, or otherwise make Twitter Content, or information derived from Twitter Content, available to any entity for the purpose of: (a) conducting or providing surveillance or gathering intelligence, including but not limited to investigating or tracking Twitter users or Twitter Content; (b) conducting or providing analysis or research for any unlawful or discriminatory purpose, or in a manner that would be inconsistent with Twitter users' reasonable expectations of privacy; (c) monitoring sensitive events (including but not limited to protests, rallies, or community organizing meetings); or (d) targeting, segmenting, or profiling individuals based on sensitive personal information, including their health (e.g., pregnancy), negative financial status or condition, political affiliation or beliefs, racial or ethnic origin, religious or philosophical affiliation or beliefs, sex life or sexual orientation, trade union membership, Twitter Content relating to any alleged or actual commission of a crime, or any other sensitive categories of personal information prohibited by law.\"\n",
    "\n",
    "**Sentiment analysis tool:** Hutto, C.J. & Gilbert, E.E. (2014). \"VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.\" *Eighth International Conference on Weblogs and Social Media (ICWSM-14)*, June 2014. [GitHub](https://github.com/cjhutto/vaderSentiment)\n",
    "\n",
    "<center> <h3>Dataset Contents*</h3> </center>\n",
    "\n",
    "<center> <h4><code>uselection_tweets_1jul_11nov.csv</code></h4> </center>\n",
    "\n",
    "| Variable | Format | Description | Example |\n",
    "| :- | :- | :- | :- | \n",
    "| `Created-At`$\\,$ | Timestamp$\\,$ | Time at which tweet was created $\\,$ | 7/1/20 7:44 PM |\n",
    "| `From-User-Id`$\\,$ | String$\\,$ | Unique identifier of the user that sent the tweet $\\,$ | 1223446325758394369 |\n",
    "| `To-User-Id`$\\,$ | String$\\,$ | Unique identifier of the user that tweet sent to, -1 if nobody $\\,$ | 387882597 |\n",
    "| `Language`$\\,$ | String$\\,$ | ISO 639-1 language of the tweet $\\,$ | en |\n",
    "| `PartyName`$\\,$ | String$\\,$ | Which party is mentioned in the tweet $\\,$ | BothParty |\n",
    "| `Id`$\\,$ | String$\\,$ | Unique identifier of the tweet $\\,$ | 1278368973948694528 |\n",
    "| `Score`$\\,$ | Float$\\,$ | The sentiment score of the tweet $\\,$ | 0.102564 |\n",
    "| `Scoring String`$\\,$ | String$\\,$ | The sentiment score of the tweet $\\,$ | 0.102564 |\n",
    "\n",
    "\\**only imported fields are shown.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-philosophy",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alike-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_cols = ['Created-At', 'From-User-Id', 'To-User-Id', 'Language', 'PartyName', 'Id', 'Score', 'Scoring String']\n",
    "twitter_filepath = os.path.join(os.getcwd(), 'data', 'twitter', 'uselection_tweets_1jul_11nov.csv')\n",
    "\n",
    "# twitter dask dataframe\n",
    "tdd = dd.read_csv(twitter_filepath, sep=';', usecols=twitter_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-novelty",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "- No duplicates found.\n",
    "\n",
    "- Extreme values were found, but were kept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-inventory",
   "metadata": {},
   "source": [
    "#### Correcting Inferred Variable Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pretty-works",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Created-At         object\n",
       "From-User-Id        int64\n",
       "To-User-Id          int64\n",
       "Language           object\n",
       "PartyName          object\n",
       "Id                  int64\n",
       "Score             float64\n",
       "Scoring String     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-damages",
   "metadata": {},
   "source": [
    "- `Created-At` should be a timestamp\n",
    "- `From-User_Id` should be a string\n",
    "- `To-User_Id` should be a string\n",
    "- `Id` should be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdd['Created-At'] = dd.to_datetime(tdd['Created-At'])\n",
    "tdd['From-User-Id'] = tdd['From-User-Id'].astype('str')\n",
    "tdd['To-User-Id'] = tdd['To-User-Id'].astype('str')\n",
    "tdd['Id'] = tdd['Id'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-parks",
   "metadata": {},
   "source": [
    "#### Remove `NaN` Values\n",
    "\n",
    "Some tweets were unscored and hence the `Scoring String` is `NaN`. These tweets were all removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agreed-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdd = tdd.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-antarctica",
   "metadata": {},
   "source": [
    "#### Initial Filters\n",
    "\n",
    "- We filter for English to get more relevant tweets; the US speaks English. Further, the experiment done later involved English Speakers.\n",
    "\n",
    "- We are primarily interested in tweets that can be fitted along the conservative-democrat political axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appointed-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdd = tdd[tdd['Language'] == 'en']\n",
    "tdd = tdd[(tdd['PartyName'] == 'Republicans') | (tdd['PartyName'] == 'Democrats')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-sector",
   "metadata": {},
   "source": [
    "#### Political Polarity\n",
    "\n",
    "- We convert the categories into numerical values by sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sharing-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = {'Republicans': -1, 'Democrats' : 1}\n",
    "\n",
    "tdd['PartyName'] = tdd['PartyName'].replace(polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-bikini",
   "metadata": {},
   "source": [
    "#### Drop Unused Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blocked-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdd = tdd.drop(columns=['Language', 'Scoring String'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-wheat",
   "metadata": {},
   "source": [
    "#### Rename and Reorder Columns\n",
    "\n",
    "No particular reason, just prefer not using dictionary to access dataframe columns and a certain order of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "difficult-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new = {\n",
    "    'Created-At'   : 'time',\n",
    "    'Id'           : 'id',\n",
    "    'From-User-Id' : 'from',\n",
    "    'To-User-Id'   : 'to',\n",
    "    'PartyName'    : 'party',\n",
    "    'Score'        : 'emotion'\n",
    "}\n",
    "\n",
    "order = ['time', 'id', 'from', 'to', 'party', 'emotion']\n",
    "\n",
    "tdd = tdd.rename(columns=old_to_new)[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-exclusive",
   "metadata": {},
   "source": [
    "#### Compute Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-devil",
   "metadata": {},
   "source": [
    "Compute all cleaning at once and get a **Pandas** Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "infrared-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdd.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-gossip",
   "metadata": {},
   "source": [
    "## 1 Political Opinion of Tweets\n",
    "\n",
    "### 1.1 How well does `party` and `emotion` capture Political Opinion? \n",
    "\n",
    "To test the accuracy of the metrics, we will take a random sample of 1000 tweets and have I and a non-author assign the tweets to the four quadrants made up of party and emotion axis. We will then apply hypothesis testing on the accuracy to confirm that the results are not up to chance (binomial distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proper-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadrant(row):\n",
    "    p = row.party\n",
    "    e = row.emotion\n",
    "    \n",
    "    if (e > 0) and (p == 1):\n",
    "        result = 1\n",
    "    elif (e < 0) and (p == -1):\n",
    "        result = 2\n",
    "    elif (e < 0) and (p == 1):\n",
    "        result = 3\n",
    "    elif (e > 0) and (p == -1):\n",
    "        result = 4\n",
    "    else:\n",
    "        result = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-shopping",
   "metadata": {},
   "source": [
    "#### Creating sample\n",
    "\n",
    "Retrieving 2000 ids as some tweets may be privated, deleted etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bigger-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = 'sample.csv'\n",
    "#tdf.id.sample(2000).to_csv(file, header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-dream",
   "metadata": {},
   "source": [
    "#### Exporting Hydrated Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "northern-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_cols = ['id', 'text']\n",
    "#sample_filepath = os.path.join(os.getcwd(), 'data', file)\n",
    "#sdf = pd.read_csv(sample_filepath, usecols=sample_cols, dtype=str)\n",
    "\n",
    "# prepare experiment\n",
    "#sdf = sdf.dropna().head(1000)\n",
    "#sdf = sdf.merge(right=tdf, how='left', on='id')\n",
    "#sdf['label'] = sdf.apply(quadrant, axis=1)\n",
    "#sdf = sdf[['id', 'text', 'label']]\n",
    "\n",
    "\n",
    "#experiment_filepath = os.path.join(os.getcwd(), 'data', 'experiment.csv')\n",
    "#sdf.to_csv(experiment_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-offset",
   "metadata": {},
   "source": [
    "#### Import Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-eligibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-tribute",
   "metadata": {},
   "source": [
    "### 1.2 Political Opinion Metric\n",
    "\n",
    "The political opinion of a tweet is the *point along the conservative-democrat political axis $[-1,1]$ that the content in the tweet expresses*. We want to convert tweets to these values as it lets us quantitively study political polarization over the time period the tweets were collected. \n",
    "\n",
    "#### `party` x Linearly Scaled `emotion`\n",
    "\n",
    "We will be scaling the `emotion` to $[-1,1]$ using minimum and maximum `emotion` values, however we do not want the outliers to have a disproportionate effect. To fix this, we will winzorise the emotion scores. Intuitively, it is unlikely that outliers are expressing particularly more emotions than the 0.01 percentile or more than the 99.99 percentile (~2500 tweets). These tweets are largely result from people repeating a certain connotated word (e.g., love or loser) that is picked up by the sentiment analysis tool leading to extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = mstats.winsorize(tdf.emotion, limits=[0.0001, 0.0001]) \n",
    "\n",
    "# maximum magnitude of emotion\n",
    "scale = max(-xs.min(), xs.max())\n",
    "\n",
    "# political opinion metric\n",
    "tdf['opinion'] = (tdf.party * xs / scale).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(tdf.opinion.sample(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-jumping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
